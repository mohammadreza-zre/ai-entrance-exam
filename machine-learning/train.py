# -*- coding: utf-8 -*-
"""task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15ya_hsobmjDjQYoMpPAvf1X9bW9R6I3J
"""

from google.colab import files
import pandas as pd

files.upload()

path = "/content/task.csv"
initialDataframe = pd.read_csv(path)

initialDataframe.head()

initialDataframe.shape

initialDataframe.info()

import matplotlib.pyplot as plt
import seaborn as sns


palette=sns.color_palette('magma')
sns.set(palette=palette)


initialDataframe['label'].value_counts().plot(kind='bar')
plt.xlabel('label')
plt.ylabel('Count')
plt.show()

initialDataframe['length']=initialDataframe['question'].apply(len)

initialDataframe['length'].plot(bins=50, kind='hist',figsize=(10,7))

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix

tfidf = TfidfVectorizer()
text = tfidf.fit_transform(initialDataframe['question'])
x_train, x_test, y_train, y_test= train_test_split(text, initialDataframe['label'], test_size=0.20, random_state=1)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

tfidf.vocabulary_

tfidf.get_feature_names()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler , MinMaxScaler , Normalizer

from sklearn.svm import SVC 
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold


from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import mean_squared_error


import warnings
warnings.filterwarnings("ignore")

"""# grid search"""

svc = SVC(random_state=42)
linear_svc = LinearSVC(random_state=42)
knn = KNeighborsClassifier()
adaboost = AdaBoostClassifier(random_state=42)
random_forest = RandomForestClassifier(random_state=42)
nb_bernoli = BernoulliNB()
nb_multinomial = MultinomialNB()

lr = LogisticRegression()
sgd = SGDClassifier(random_state=42)






params_svc = {'kernel' : ['rbf'] , 'C' : [0.1 , 1 ,10,100,1000] , 'gamma' : [0.1 , 0.01 , 0.001]} #, 'poly', 'rbf', 'sigmoid', 'precomputed'
params_linear_svc ={'penalty' : [ 'l2'] , 'C' : [0.1 , 1 ,10,100,1000] }
params_knn = {'n_neighbors' :[2,4,6,8,10,12,14,16,18] , 'metric' : ['minkowski' , "euclidean","manhattan"] ,  "weights": ["uniform","distance"] , "leaf_size": [1,3,5,12,30]}
params_adaboost = {'n_estimators' :[10,20,30,40,50]}
params_random_forest = {'n_estimators' :[60,80,100,120,140] , 'criterion' : ['gini' , 'entropy'] , 'min_samples_leaf' : [1,3,10] , 'max_features' : [1,3,10] , 'min_samples_split' : [2,3,10]}
params_nb_gaussian = {}
params_nb_bernoli = {}
params_lr = {'penalty': ['l1' , 'l2' , 'None']  , 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}
params_sgd = {'penalty' : ['l2', 'l1', 'elasticnet'] , 'alpha' : [0.1 , 0.01 , 0.001 , 0.0001]}





models = [sgd,linear_svc,knn,adaboost ,random_forest,lr,svc,nb_bernoli]
models_name = ['sgd','linear svc','knn','adaboost' ,'random forest' ,'lr','svc','bayes bernoli' ]
models_params = [params_sgd,params_linear_svc,params_knn,params_adaboost ,params_random_forest
                ,params_lr,params_svc,params_nb_bernoli]

def calculation(model , xtrain , xtest , ytrain , ytest) :

  model.fit(xtrain , ytrain)
  y_pred_test = model.predict(xtest)
  y_pred_train = model.predict(xtrain)


  accuracy_score_train = accuracy_score(ytrain ,y_pred_train)
  accuracy_score_test = accuracy_score(ytest , y_pred_test)
  roc_score = roc_auc_score(ytest , y_pred_test)
  choosen_estimatore = model.best_estimator_
  mse_error = mean_squared_error(ytest , y_pred_test)
  clf_report = classification_report(ytest , y_pred_test)
  conf_matrix = confusion_matrix(ytest , y_pred_test)



  print("----------------------------")
  print(f'train accuracy score : {accuracy_score_train}')
  print("----------------------------") 
  print(f'acuuracy score test : {accuracy_score_test}')
  print("----------------------------")
  print(f'roc auc score : {roc_score}')
  print("----------------------------")
  print(f'mean square error : {mse_error}')
  print("----------------------------")
  print(f'best estimator :\n{choosen_estimatore}')
  print("----------------------------")
  print(f'classification  report :\n{clf_report}')




  acc_train.append(accuracy_score_train)
  acc_test.append(accuracy_score_test)
  acc_roc.append(roc_score)
  mse.append(mse_error)
  best_estimators.append(choosen_estimatore)
  clfs.append(clf_report)



  sns.set_style("dark")
  fig_score , ax_score = plt.subplots(nrows=1 , ncols=2 , figsize=(12,6))
  ax_score[0].set_title('confusion matrix')
  plot_confusion_matrix(ax=ax_score[0] , estimator=model , X=xtest , y_true=ytest  , cmap='autumn' )
  fpr , tpr , thresh = roc_curve(ytrain ,y_pred_train)
  ax_score[1].plot(fpr , tpr ,  color='darkturquoise' , label = 'train')
  fpr , tpr , thresh = roc_curve(ytest , y_pred_test )
  ax_score[1].plot(fpr , tpr , color='lightcoral' , label = 'test')

  ax_score[1].legend(loc='lower right')
  ax_score[1].set_title('roc curve')
  ax_score[1].plot([0,1] , [0,1] , color='black' , linestyle='--' )

  fig_score.suptitle(models_name[i] , size = 20)

  plt.show()
  print('\n\n')

acc_train = []
acc_test = []
acc_roc = []
mse = []
best_estimators = []
clfs  = []



for i in range(len(models)):
# for (model,name,param) in zip(models , models_name , models_params):
  clf = GridSearchCV(estimator=models[i] ,
                     param_grid=models_params[i] ,
                     cv=StratifiedKFold(n_splits=10),
                     scoring='accuracy',
                     n_jobs=-1,
                     )
  
  print('*********************************************************************************************')
  print(f'**************************************{models_name[i]}******************************************')
  print('*********************************************************************************************')


  calculation(model=clf , xtrain=x_train , xtest=x_test , ytrain=y_train , ytest=y_test)

result_df = pd.DataFrame({'models' : models_name ,'acc train' : acc_train,'acc test' : acc_test,'acc roc' : acc_roc,'mse' : mse})

result_df.index = result_df['models']
result_df = result_df.drop(['models'] , axis=1)


f , ax = plt.subplots(figsize=(5,7))

sns.heatmap(result_df,
            cmap='RdGy' , 
            annot=True ,
            annot_kws={'size' : 12},
            cbar=False)
plt.title("*Grid Search Results*" , size = 20)
plt.xticks(size=15 ,rotation=20 )
plt.yticks(size=15 ,rotation=20 )
plt.show()

sort_cv = result_df.reset_index().sort_values('acc test' , ascending=False)[:4]
print(sort_cv)

ff ,axx = plt.subplots(nrows=1 , ncols=4 , figsize=(30,10))
ff.suptitle('best models' , size=40)

for (i,index) in enumerate((2,6,3,0)):
  plot_confusion_matrix(best_estimators[index] , X=x_test , y_true=y_test ,ax=axx[i] , cmap='gray_r' , )
  axx[i].set_title(label=models_name[index] ,size=24 )

plt.show()